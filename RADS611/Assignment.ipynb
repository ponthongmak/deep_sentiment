{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">Wanchana Ponthongmak<br>\n",
    "6136168 RADS/D<br>\n",
    "RADS611 Advance Modeling</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Sentiment Analysis by Deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b>Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-indent: 2.5em;\">\n",
    "    One of the most important elements for businesses is to understand what their customers or clients think about the products or services that they create (customer's voice). The business owner will be able to improve their products and services with more cost-effectiveness. Thanks to the advent of online social networks which has produced online customer expression of the products or services. The sentiment analysis is one way to extract customer opinion.\n",
    "<p style=\"text-indent: 2.5em;\">\n",
    "    Sentiment analysis is also known as opinion mining is a field within Natural Language Processing (NLP) which builds systems to identify and extract opinions within sentences. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.\n",
    "<p style=\"text-indent: 2.5em;\"> \n",
    "    This study objective is to understand the opinion of patients in three large university hospitals, including Ramathibodi hospital, Siriraj hospital, and Chulalongkorn hospital and use that knowledge to improve a hospital business through creating a development plan. The patient's comments on social media are retrieved then summarize them into two groups, positive attitude, and negative attitude. The deep learning approaches are used to create a model to predict the patient's opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b>Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1.  Patient's comment retrieval from internet\n",
    "<p style=\"text-indent: 2.5em;\">\n",
    "    The patient's comment of three hospitals were retrieved from www.honestdocs.co with satisfaction score range from one (low satisfaction) to five (high satisfaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">2.  Translate the comments into English\n",
    "<p style=\"text-indent: 2.5em;\">\n",
    "    Since the www.honestdocs.co reviews all Thai's hospital, most of the comments are written in Thai. In this study, we aim to analyze the sentences in English. As a result, we used Google cloud translate API to translate Thai's comments into English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">3.  Preprocessing data\n",
    "<p style=\"text-indent: 2.5em;\">\n",
    "    There are xxx steps in order to prepare data to feed into deep learning model\n",
    "    1) merging database\n",
    "    2) deduplication\n",
    "    3) class labeling\n",
    "    4) class balancing\n",
    "    5) data preprocessing\n",
    "        a) lower case\n",
    "        b) negation handling\n",
    "        c) lemmatization\n",
    "        d) punctuation removing\n",
    "        e) stopword removing\n",
    "        f) sequence padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) data spliting\n",
    "<p style=\"text-indent: 2.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) pre-train network preparing\n",
    "<p style=\"text-indent: 2.5em;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8) model experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b>Get start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GL63\\OneDrive\\RADS611\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GRU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.externals import joblib\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from google.cloud import translate\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Patient's comment retrieval from internet\n",
    "## 2) Translate the comments into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create google credential key for accessing google cloud API\n",
    "credential_path = r\"data\\ID.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define url to download\n",
    "url_rama = 'https://www.honestdocs.co/hospitals/ramathibodi-hospital'\n",
    "url_siri = 'https://www.honestdocs.co/hospitals/siriraj-hospital'\n",
    "url_chula = 'https://www.honestdocs.co/hospitals/king-chulalongkorn-memorial-hospital'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create def for downloading patient's comment on website and translate to English\n",
    "def tran2eng(url):\n",
    "    # set variable to store comment and score\n",
    "    comment = []\n",
    "    score = []\n",
    "    for i in range(100):\n",
    "        r = requests.get(url, params=dict(query=\"web scraping\",page=i))\n",
    "        soup = bs(r.text,'html.parser')\n",
    "        j = len(soup.find_all('div',{'class':'comments__content'})) # count number of comments\n",
    "        for i in range(j): \n",
    "            comment.append(soup.find_all('div',{'class':'comments__content'})[i].get_text())\n",
    "            score.append(soup.find_all('span',{'class':'stars star-rating'})[i].attrs['data-score'])\n",
    "            i +=1\n",
    "        i +=1\n",
    "        if len(soup.find_all('div',{'class':'comments__content'})) <= 0:\n",
    "            break       \n",
    "    df = pd.DataFrame({'comment': comment, 'score' : score})  \n",
    "    # Instantiates a client\n",
    "    translator = translate.Client()\n",
    "    df['en_com'] = df['comment'].apply(translator.translate, target_language='en').apply(lambda x : x['translatedText'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and translate comment to dataset\n",
    "rama = tran2eng(url_rama)\n",
    "siri = tran2eng(url_siri)\n",
    "chula = tran2eng(url_chula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data set\n",
    "rama.to_csv(r\"data\\rama.csv\", sep=';', index=False, encoding='utf-8', chunksize=100)\n",
    "siri.to_csv(r\"data\\siri.csv\", sep=';', index=False, encoding='utf-8', chunksize=100)\n",
    "chula.to_csv(r\"data\\chula.csv\", sep=';', index=False, encoding='utf-8', chunksize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set \n",
    "    # use for creating quick initial dataset \n",
    "rama = pd.read_csv(r\"data\\rama.csv\", sep = ';')\n",
    "siri = pd.read_csv(r\"data\\siri.csv\", sep = ';')\n",
    "chula = pd.read_csv(r\"data\\chula.csv\", sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
